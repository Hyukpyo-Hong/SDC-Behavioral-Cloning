{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "#Normalize\n",
    "def normalize(image_data):\n",
    "    a = -1\n",
    "    b = 1\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "#Resizing\n",
    "from scipy.misc import imread\n",
    "import scipy.misc as sp\n",
    "def resize_and_crop():\n",
    "\n",
    "    length = len(y_train)\n",
    "    shape = (80,160)\n",
    "    \n",
    "    for i, loc in zip(range(length),data['img']):        \n",
    "        image = imread(loc)        \n",
    "        image = sp.imresize(image, size=shape, interp='cubic')\n",
    "        X_train[i] = image[27:65,:]              \n",
    "        print(\"Resize and crop: \",i,\"/\",length)        \n",
    "    print(\"Images size become :\",X_train[0].shape)\n",
    "\n",
    "    \n",
    "#Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D   \n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "def model_1():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(24, 5, 5,input_shape=(80, 160, 3),subsample=(2, 2)))\n",
    "\tmodel.add(Convolution2D(36, 5, 5,subsample=(2, 2)))\n",
    "\tmodel.add(Convolution2D(48, 5, 5,subsample=(2, 2)))\n",
    "\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100,activation='relu'))\n",
    "\tmodel.add(Dense(50,activation='relu'))\n",
    "\tmodel.add(Dense(10))\n",
    "\tmodel.add(Dense(1))\n",
    "\treturn model\n",
    "\n",
    "def model_2():\n",
    "\tmodel = Sequential()\n",
    "\t#input(80,160,3) output(24,88,24)\n",
    "\tmodel.add(Convolution2D(24, 5, 5,input_shape=(80, 160, 3),subsample=(2, 2)))\t\n",
    "\tmodel.add(Dropout(0.5))\t\n",
    "\tmodel.add(Convolution2D(36, 5, 5,subsample=(2, 2)))\t\n",
    "\tmodel.add(Dropout(0.5))\t\n",
    "\tmodel.add(Convolution2D(48, 5, 5,subsample=(2, 2)))\t\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Convolution2D(64, 3, 3))\t\t\n",
    "\tmodel.add(Convolution2D(64, 3, 3))\t\t\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100,activation='relu'))\n",
    "\tmodel.add(Dense(50,activation='relu'))\n",
    "\tmodel.add(Dense(10))\n",
    "\tmodel.add(Dense(1))\n",
    "\treturn model\n",
    "\n",
    "def model_3():\n",
    "    model = Sequential()\n",
    "    elu = ELU(alpha=1.0)\n",
    "    #input(38,160,3) output(36,88,24)\n",
    "    model.add(Convolution2D(24, 3, 3,input_shape=(38, 160, 3),name='C1'))\n",
    "    model.add(elu)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(36, 5, 5,name='C2'))\n",
    "    model.add(elu)              \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(48, 5, 5,name='C3'))\n",
    "    model.add(elu)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3,name='C4'))\n",
    "    model.add(elu)\n",
    "    model.add(Convolution2D(64, 3, 3,name='C5'))\n",
    "    model.add(elu)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100,activation='tanh',name='L1'))\n",
    "    model.add(Dense(50,activation='tanh',name='L2'))\n",
    "    model.add(Dense(10,name='L3'))\n",
    "    model.add(Dense(1,name='L4'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize and crop:  0 / 3\n",
      "Resize and crop:  1 / 3\n",
      "Resize and crop:  2 / 3\n",
      "Images size become : (38, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "\n",
    "#mydata\n",
    "#data = np.genfromtxt('./driving_log_main.csv',dtype=[('img','U110'),('angle','f8')],delimiter=\",\",usecols=(0,3))\n",
    "#dummy\n",
    "data = np.genfromtxt('./dummy.csv',dtype=[('img','U110'),('angle','f8')],delimiter=\",\",usecols=(0,3))\n",
    "#udacity data\n",
    "#data = np.genfromtxt('./data/driving_log.csv',dtype=[('img','U110'),('angle','f8')],delimiter=\",\",usecols=(0,3), skip_header=1)\n",
    "\n",
    "y_train = data['angle']\n",
    "X_train = np.empty([len(y_train),38,160,3]).astype(np.uint8) \n",
    "\n",
    "#resize and crop\n",
    "resize_and_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomalizing starts\n",
      "Nomalizing finished.\n",
      "Train on 2 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 2s - loss: 0.2757 - acc: 0.5000 - val_loss: 37.8084 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s - loss: 34.0227 - acc: 0.0000e+00 - val_loss: 24.4681 - val_acc: 0.0000e+00\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Shuffle\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train) \n",
    "\n",
    "#Pre-processing\n",
    "print(\"Nomalizing starts\")\n",
    "X_normalized = normalize(X_train)\n",
    "print(\"Nomalizing finished.\\n\")\n",
    "\n",
    "#Complie\n",
    "Learning_Rate=0.001\n",
    "model = model_3()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "#Train\n",
    "history = model.fit(X_normalized, y_train, \n",
    "\tnb_epoch=2, \n",
    "\tvalidation_split=0.05)\n",
    " \t\n",
    "#Save Model\n",
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "json_str = model.to_json()\n",
    "with open('model.json','w') as f:\n",
    "    json.dump(json_str, f)\n",
    "model.save_weights('model.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
